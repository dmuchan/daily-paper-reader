{
  "mode": "standard",
  "generated_at": "2026-02-12T19:37:55.786857+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 1,
    "deep_divecandidates": 2,
    "deep_cap": 6,
    "deep_selected": 2,
    "quick_candidates": 3,
    "quick_skim_target": 11,
    "quick_selected": 3
  },
  "deep_dive": [
    {
      "id": "2602.10576v1",
      "title": "LLM-Based Scientific Equation Discovery via Physics-Informed Token-Regularized Policy Optimization",
      "abstract": "Symbolic regression aims to distill mathematical equations from observational data. Recent approaches have successfully leveraged Large Language Models (LLMs) to generate equation hypotheses, capitalizing on their vast pre-trained scientific priors. However, existing frameworks predominantly treat the LLM as a static generator, relying on prompt-level guidance to steer exploration. This paradigm fails to update the model's internal representations based on search feedback, often yielding physically inconsistent or mathematically redundant expressions. In this work, we propose PiT-PO (Physics-informed Token-regularized Policy Optimization), a unified framework that evolves the LLM into an adaptive generator via reinforcement learning. Central to PiT-PO is a dual-constraint mechanism that rigorously enforces hierarchical physical validity while simultaneously applying fine-grained, token-level penalties to suppress redundant structures. Consequently, PiT-PO aligns LLM to produce equations that are both scientifically consistent and structurally parsimonious. Empirically, PiT-PO achieves state-of-the-art performance on standard benchmarks and successfully discovers novel turbulence models for challenging fluid dynamics problems. We also demonstrate that PiT-PO empowers small-scale models to outperform closed-source giants, democratizing access to high-performance scientific discovery.",
      "authors": [
        "Boxiao Wang",
        "Kai Li",
        "Tianyi Liu",
        "Chen Li",
        "Junzhe Wang",
        "Yifan Zhang",
        "Jian Cheng"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 07:02:23+00:00",
      "link": "https://arxiv.org/pdf/2602.10576v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 10.0,
      "llm_evidence_en": "LLM-based symbolic regression with RL and physics priors",
      "llm_evidence_cn": "基于大模型、强化学习和物理先验的符号回归",
      "llm_evidence": "基于大模型、强化学习和物理先验的符号回归",
      "llm_tldr_en": "Proposes PiT-PO, using RL to evolve LLMs for adaptive and physically consistent scientific equation discovery.",
      "llm_tldr_cn": "提出 PiT-PO 框架，利用强化学习演化大模型，实现自适应且符合物理规律的方程发现。",
      "llm_tldr": "提出 PiT-PO 框架，利用强化学习演化大模型，实现自适应且符合物理规律的方程发现。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.10480v1",
      "title": "Neuro-Symbolic Synergy for Interactive World Modeling",
      "abstract": "Large language models (LLMs) exhibit strong general-purpose reasoning capabilities, yet they frequently hallucinate when used as world models (WMs), where strict compliance with deterministic transition rules--particularly in corner cases--is essential. In contrast, Symbolic WMs provide logical consistency but lack semantic expressivity. To bridge this gap, we propose Neuro-Symbolic Synergy (NeSyS), a framework that integrates the probabilistic semantic priors of LLMs with executable symbolic rules to achieve both expressivity and robustness. NeSyS alternates training between the two models using trajectories inadequately explained by the other. Unlike rule-based prompting, the symbolic WM directly constrains the LLM by modifying its output probability distribution. The neural WM is fine-tuned only on trajectories not covered by symbolic rules, reducing training data by 50% without loss of accuracy. Extensive experiments on three distinct interactive environments, i.e., ScienceWorld, Webshop, and Plancraft, demonstrate NeSyS's consistent advantages over baselines in both WM prediction accuracy and data efficiency.",
      "authors": [
        "Hongyu Zhao",
        "Siyu Zhou",
        "Haolin Yang",
        "Zengyi Qin",
        "Tianyi Zhou"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-11 03:36:18+00:00",
      "link": "https://arxiv.org/pdf/2602.10480v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 8.0,
      "llm_evidence_en": "Neuro-symbolic synergy for world modeling",
      "llm_evidence_cn": "用于世界建模的神经符号协同",
      "llm_evidence": "用于世界建模的神经符号协同",
      "llm_tldr_en": "Integrates LLMs with symbolic rules for robust world modeling, directly aligning with neuro-symbolic queries.",
      "llm_tldr_cn": "将大模型与符号规则结合进行建模，直接符合神经符号研究查询。",
      "llm_tldr": "将大模型与符号规则结合进行建模，直接符合神经符号研究查询。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ]
    }
  ],
  "quick_skim": [
    {
      "id": "2602.10191v1",
      "title": "Machine Learning Methods for Stellar Collisions. I. Predicting Outcomes of SPH Simulations",
      "abstract": "Stellar collisions can occur frequently in dense cluster environments, and play a crucial role in producing exotic phenomena from blue stragglers in globular clusters to high-energy transients in galactic nuclei. Successive collisions and mergers of massive stars could also lead to the formation of massive black holes, serving as seeds for supermassive black hole in the early universe. While analytic fitting formulae exist for predicting collision outcomes, they do not generalize across different energy scales or stellar evolutionary phases. Smoothed particle hydrodynamics (SPH) simulations are often used to compute the outcomes of stellar collisions, but, even at low resolution, their computational cost makes running on-the-fly calculations during an $N$-body simulation quite challenging. Here we present a new grid of $27,720$ SPH calculations of main-sequence star collisions, spanning a wide range of masses, ages, relative velocities, and impact parameters. Using this grid, we train machine learning models to predict both collision outcomes (merger vs disruption, or flyby) and final remnant masses. We compare the performance of nearest neighbors, support vector machines, and neural networks, achieving classification balanced accuracy of $98.4\\%$, and regression relative errors as low as $0.11\\%$ and $0.15\\%$ for the final stars $1$ and $2$, respectively. We make our trained models publicly available as part of the package collAIder, enabling rapid predictions of stellar collision outcomes in $N$-body models of dense star cluster dynamics.",
      "authors": [
        "Elena González Prieto",
        "James C. Lombardi,",
        "Sanaea C. Rose",
        "Charles F. A. Gibson",
        "Christopher E. O'Connor",
        "Tjitske Starkenburg",
        "Fulya Kıroğlu",
        "Kyle Kremer",
        "Tristan C. Parmerlee",
        "Frederic A. Rasio"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "astro-ph.GA",
        "astro-ph.IM",
        "astro-ph.SR"
      ],
      "published": "2026-02-10 19:00:01+00:00",
      "link": "https://arxiv.org/pdf/2602.10191v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Predicting outcomes of stellar collisions",
      "llm_evidence_cn": "预测恒星碰撞结果",
      "llm_evidence": "预测恒星碰撞结果",
      "llm_tldr_en": "Uses ML to predict stellar collision outcomes where analytic formulae are limited, relevant to physics discovery.",
      "llm_tldr_cn": "在解析公式受限的情况下使用机器学习预测恒星碰撞，与物理发现相关。",
      "llm_tldr": "在解析公式受限的情况下使用机器学习预测恒星碰撞，与物理发现相关。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.10233v1",
      "title": "ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise",
      "abstract": "Recent advances in LLM-guided evolutionary computation, particularly AlphaEvolve, have demonstrated remarkable success in discovering novel mathematical constructions and solving challenging optimization problems. In this article, we present ImprovEvolve, a simple yet effective technique for enhancing LLM-based evolutionary approaches such as AlphaEvolve. Given an optimization problem, the standard approach is to evolve program code that, when executed, produces a solution close to the optimum. We propose an alternative program parameterization that maintains the ability to construct optimal solutions while reducing the cognitive load on the LLM. Specifically, we evolve a program (implementing, e.g., a Python class with a prescribed interface) that provides the following functionality: (1) propose a valid initial solution, (2) improve any given solution in terms of fitness, and (3) perturb a solution with a specified intensity. The optimum can then be approached by iteratively applying improve() and perturb() with a scheduled intensity. We evaluate ImprovEvolve on challenging problems from the AlphaEvolve paper: hexagon packing in a hexagon and the second autocorrelation inequality. For hexagon packing, the evolved program achieves new state-of-the-art results for 11, 12, 15, and 16 hexagons; a lightly human-edited variant further improves results for 14, 17, and 23 hexagons. For the second autocorrelation inequality, the human-edited program achieves a new state-of-the-art lower bound of 0.96258, improving upon AlphaEvolve's 0.96102.",
      "authors": [
        "Alexey Kravatskiy",
        "Valentin Khrulkov",
        "Ivan Oseledets"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI",
        "math.CA",
        "math.MG",
        "math.OC"
      ],
      "published": "2026-02-10 19:23:13+00:00",
      "link": "https://arxiv.org/pdf/2602.10233v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "LLM-guided evolutionary computation for mathematical discovery",
      "llm_evidence_cn": "大模型引导的数学发现演化计算",
      "llm_evidence": "大模型引导的数学发现演化计算",
      "llm_tldr_en": "Enhances LLM-based evolutionary algorithms to discover novel mathematical constructions and solutions.",
      "llm_tldr_cn": "增强了大模型演化算法，用于发现新的数学结构和优化解。",
      "llm_tldr": "增强了大模型演化算法，用于发现新的数学结构和优化解。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.10598v1",
      "title": "Neuro-symbolic Action Masking for Deep Reinforcement Learning",
      "abstract": "Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with given domain constraints of high-dimensional states, in a minimally supervised manner during the DRL process. Based on the learned symbolic model of states, NSAM learns action masks that rules out infeasible actions. NSAM enables end-to-end integration of symbolic reasoning and deep policy optimization, where improvements in symbolic grounding and policy learning mutually reinforce each other. We evaluate NSAM on multiple domains with constraints, and experimental results demonstrate that NSAM significantly improves sample efficiency of DRL agent while substantially reducing constraint violations.",
      "authors": [
        "Shuai Han",
        "Mehdi Dastani",
        "Shihan Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-11 07:42:53+00:00",
      "link": "https://arxiv.org/pdf/2602.10598v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Neuro-symbolic framework for learning symbolic models",
      "llm_evidence_cn": "用于学习符号模型的神经符号框架",
      "llm_evidence": "用于学习符号模型的神经符号框架",
      "llm_tldr_en": "Proposes a neuro-symbolic framework to automatically learn symbolic models for action masking in reinforcement learning.",
      "llm_tldr_cn": "提出一种神经符号框架，在强化学习中自动学习符号模型以进行动作掩码。",
      "llm_tldr": "提出一种神经符号框架，在强化学习中自动学习符号模型以进行动作掩码。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "6"
    }
  ]
}