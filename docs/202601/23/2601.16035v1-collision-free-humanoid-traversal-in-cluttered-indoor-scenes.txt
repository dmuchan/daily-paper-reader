Title: Collision-Free Humanoid Traversal in Cluttered Indoor Scenes

URL Source: https://arxiv.org/pdf/2601.16035v1

Published Time: Fri, 23 Jan 2026 02:02:50 GMT

Number of Pages: 9

Markdown Content:
# Collision-Free Humanoid Traversal in Cluttered Indoor Scenes 

Han Xue 1,3âˆ—, Sikai Liang 2,3âˆ—, Zhikai Zhang 1,3âˆ—, Zicheng Zeng 3,5, Yun Liu 1,3, Yunrui Lian 1,3, Jilong Wang 3,6,Qingtao Liu 3, Xuesong Shi 3, and Li Yi â€ ,1,4

Fig. 1: Using a single generalist policy, our humanoid robot achieves collision-free traversal in cluttered indoor environments, including (a) detouring through narrow passages, (b) crouching under low-hanging obstacles, (c) squeezing through tight indoor spaces, and (d) hurdling over objects scattered on the floor. 

Abstract â€” We study the problem of collision-free humanoid traversal in cluttered indoor scenes, such as hurdling over objects scattered on the floor, crouching under low-hanging obstacles, or squeezing through narrow passages. To achieve this goal, the humanoid needs to map its perception of sur-rounding obstacles with diverse spatial layouts and geometries to the corresponding traversal skills. However, the lack of an effective representation that captures humanoidâ€“obstacle relationships during collision avoidance makes directly learning such mappings difficult. We therefore propose Humanoid Po-tential Field (HumanoidPF), which encodes these relationships as collision-free motion directions, significantly facilitating RL-based traversal skill learning. We also find that HumanoidPF exhibits a surprisingly negligible sim-to-real gap as a perceptual representation. To further enable generalizable traversal skills through diverse and challenging cluttered indoor scenes, we fur-ther propose a hybrid scene generation method, incorporating crops of realistic 3D indoor scenes and procedurally synthesized obstacles. We successfully transfer our policy to the real world and develop a teleoperation system where users could command the humanoid to traverse in cluttered indoor scenes with just       

> *Equal Contributions, â€ Corresponding Author
> 1Tsinghua University, 2Tongji University, 3Galbot, 4Shanghai Qi Zhi Institute, 5South China University of Technology, 6Peking University

a single click. Extensive experiments are conducted in both simulation and the real world to validate the effectiveness of our method. Demos and code can be found in our website: https://axian12138.github.io/CAT/. 

I. I NTRODUCTION 

Consider a domestic humanoid robot needs to frequently traverse between the bedroom, living room, and kitchen to perform household chores. A key challenge for the robot is to avoid collisions with the surrounding environment during movement, preventing potential damage to the robot itself or the environment. In cluttered indoor scenes, the humanoid may need to hurdle over objects scattered on the floor, crouch under low-hanging obstacles, or squeeze through narrow passages. This requires the robot to perceive the environment and map obstacles with diverse spatial layouts and geometries to the corresponding traversal skills. While legged locomotion in complex environments has seen remarkable advances for quadrupeds [1]â€“[13] and hu-manoids [14]â€“[24], existing works are often limited in their ability to handle traversal in cluttered indoor scenes (full-

> arXiv:2601.16035v1 [cs.RO] 22 Jan 2026

spatial obstacle layouts and intricate, realistic geometries), as shown in Table I. These limitations collectively point to the lack of an effective representation for humanoidâ€“obstacle re-lationships during collision avoidance: (i) existing works [8]â€“ [13], [15], [23] typically obtain penalty signals only when collisions occur, yielding sparse and delayed supervision. This forces reinforcement learning (RL) to depend on in-efficient trial-and-error exploration, thus calling for a repre-sentation that can provide anticipatory and dense guidance; (ii) conventional representations expose the policy to raw, high-dimensional environmental measurement independently of humanoidâ€“obstacle spatial relationships, forcing the pol-icy to infer traversal decisions through implicit kinematic reasoning. To bridge these gaps, we introduce Humanoid Poten-tial Field (HumanoidPF ), an informative representation that encodes humanoidâ€“obstacle relationships for collision avoidance. Inspired by classical Artificial Potential Fields (APF) [25], HumanoidPF models how the humanoid is influ-enced by and should react to its surrounding environment as a continuous and differentiable gradient field, inducing â€œvirtual forcesâ€ that point toward collision-free motion directions. We seamlessly integrate HumanoidPF into traversal skill learning in two complementary ways. First, HumanoidPF serves as the policy observation by being queried at multiple key body parts, providing directional cues that indicate how each part should move to avoid obstacles and advance toward the goal. This allows the policy to reason directly over traversal decisions, instead of inferring collision-avoidance behavior from raw, high-dimensional visual inputs. Second, HumanoidPF streamlines collision-aware reward design. The field induces a distribution over preferred motion directions, and the policy is encouraged to align its motion with this distribution. This provides anticipatory and sufficient super-vision for RL models, while exhibiting strong cross-scene generalization without manual reward tuning. Moreover, we observe that HumanoidPF yields a surprisingly negligible sim-to-real gap as a perceptual representation. Its continuous field formulation naturally functions as a low-pass perceptual filter, smoothing out isolated perception artifacts and promot-ing robust sim-to-real transfer. To learn traversal skills with HumanoidPF across diverse and challenging obstacle configurations, we propose a hybrid scene generation strategy that systematically expands the space of training scenarios. By augmenting crops of realistic 3D indoor datasets with procedurally synthesized highly constrained obstacles, we expose the robot to a curriculum of challenging clutter configurations that are rarely present in existing datasets, enabling it to acquire rich collision-avoidance experience and substantially improving robustness in near-collision and emergency scenarios. We further instantiate our approach into a practical teleop-eration system, termed Click-and-Traverse (CAT), where the user can simply click a goal to command the humanoid to safely traverse cluttered indoor environments. Extensive ex-periments in both simulation and realistic real-world indoor scenes validate the practical applicability of HumanoidPF                                 

> Method Spatial layouts Intricate geometries PIM [18] ğ‘† ={ğ‘” }âœ—
> HumanoidParkour [15] ğ‘† ={ğ‘” }âœ—
> BeamDojo [21] ğ‘† ={ğ‘” }âœ—
> Vb-com [19] ğ‘† âŠ‚ { ğ‘”, ğ‘™ },|ğ‘† |=1âœ—
> Gallant [23] ğ‘† âŠ‚ { ğ‘”, ğ‘™, ğ‘œ },|ğ‘† |=1âœ—
> Ours ğ‘† ={ğ‘”, ğ‘™, ğ‘œ }âœ“

TABLE I: Overall comparison with existing works. ğ‘† : Spa-tial layouts. ğ‘”, ğ‘™, ğ‘œ : Ground, lateral and overhead obstacles. and its strong generalization across diverse environments. Our contributions are fourfold:  

> â€¢

To the best of our knowledge, we are the first to systematically study collision-free humanoid traversal in cluttered indoor scenes , advancing toward real-world domestic humanoid robot application.  

> â€¢

We propose HumanoidPF , an informative represen-tation that explicitly encodes humanoidâ€“obstacle re-lationships for collision avoidance, thus significantly facilitating RL-based traversal skill learning.  

> â€¢

We propose a hybrid scene generation strategy that exposes the policy to realistic, diverse and challenging cluttered scenarios, significantly improving robustness and generalization in complex indoor environments.  

> â€¢

We successfully transfer our policy to the real world as a convenient and useful teleoperation system to command the humanoid to traverse in cluttered indoor scenes. II. R ELATED WORKS 

A. Legged locomotion in complex environments 

Legged robots are expected to perform stable locomotion in complex environments, including challenging terrains and obstacles. Quadruped robots have demonstrated robust park-our capabilities on highly challenging terrains [1]â€“[7] and confined or cluttered spaces [8]â€“[13]. Humanoids have also demonstrated the ability to navigate in height-constrained environments [14] and advanced locomotion skills against risky terrains or obstacles, such as stepping stairs, balance beams, and stepping stones [15]â€“[24]. However, existing works on humanoids often limited to obstacles with partial spatial layouts (e.g. terrains [15]â€“[22], [24], or over-hanging obstacles [14]) and simple geometries (e.g. rectangular blocks [14]â€“[17], [20]â€“[22], or regular polyhedra [19], [23]). Notably, while Gallant [23] addresses ground, lateral, and overhead obstacle layouts in isolation, it does not consider scenarios where these constraints coexist. In contrast, our method constructs HumanoidPF to operate in cluttered indoor scenes where full-spatial constraints are jointly present with highly intricate geometries. The compar-ison of existing works and our work is shown in Table I. 

B. Artificial potential field for obstacle avoidance 

Originally introduced in the late 1980s, the Artificial Potential Field (APF) [25] method generates a virtual force field to guide the motion of manipulators or mobile robots for obstacle avoidance. Inspired by physical analogies, the goal Fig. 2: Overall pipeline. We learn a visuomotor policy that maps diverse obstacle geometries and spatial layouts to corresponding whole-body traversal skills. Left: HumanoidPF for whole-body traversal learning. (Top) Construction of HumanoidPF, a reformulation of APF tailored for humanoid whole-body traversal; (Bottom) its use as informative perceptual representation and collision-avoidance rewards. Right: Scalable training and deployment pipeline. (Top) Hybrid scene generation for constructing diverse and challenging training environments; (Middle) parallel training of multiple specialist policies followed by distillation into a single generalist policy; (Bottom) sim-to-real deployment via Click-and-Traverse ,enabling intuitive loco-navigation teleoperation in cluttered indoor scenes. Sections III-A, III-B and III-C provide detailed descriptions of the HumanoidPF for traversal learning, the scalable training, and deployment pipeline, respectively. position is modeled as an attractive pole, while obstacles act as repulsive surfaces. Traditionally, APF has been widely used in 2D path planning for mobile robots [26]â€“[28] and robotic manipulators [29]â€“[31]. However, only a few studies have combined model-based quadruped control with APF in limited forms by abstracting the center of mass [32], [33] or foot joint [34], [35] as a single rigid body, which is insufficient to handle the complex planning and control challenges of humanoid learning. In contrast, we propose HumanoidPF , a principled reformula-tion of APF specifically tailored for informative perception and reward streamlining of humanoid skill learning. III. M ETHOD 

We study the problem of collision-free humanoid traversal in cluttered indoor scenes. Given a target position g âˆˆ R3,and a set of indoor obstacles O = {ğ‘‚ ğ‘– }ğ‘ ğ‘– =1, the humanoid needs to move to g without any collision with O. To solve this problem, the humanoid needs to map its perception of surrounding obstacles to the corresponding traversal skills. Our method can be split into two parts. We first introduce how our HumanoidPF encodes humanoidâ€“obstacle relation-ships to facilitate humanoid traversal learning in Section III-A. We further introduce how to generalize our policy to diverse and challenging indoor scenes with our proposed hybrid scene generation method in Section III-B. For real-world deployment, we further instantiate our approach as a teleoperated loco-navigation system, which is presented in Section III-C. The overall pipeline is shown in Figure 2. 

A. HumanoidPF for whole-body traversal learning 

We substantially extend classical APF to support learning-based whole-body humanoid traversal. In APF, the target location g is modeled as an attractive pole and obstacles O

as repulsive surfaces, forming a gradient field that indicates collision-free motion toward the goal. However, prior works directly apply APF in single-rigid-body model-based control, which is inadequate for the high-dimensional and tightly coupled planning and control demands of humanoid skill learning. We therefore propose HumanoidPF, a principled reformulation of APF tailored for humanoid, which encodes humanoidâ€“obstacle relationships for informative perception and reward streamlining. 

1) HumanoidPF construction 

We begin by constructing the attractive field ğ‘ˆ att :

ğ‘ˆ att (x) = ğœ‚ âˆ¥x âˆ’ gâˆ¥geo , (1) where the geodesic distance âˆ¥xâˆ’gâˆ¥geo represents the shortest 3D path from position x to the goal g without intersecting obstacles, and ğœ‚ is a scaling factor. The geodesic distance Fig. 3: (a) Construction of the APF and (b) motion prior distribution induced by the HumanoidPF. inherently accounts for obstacle geometry, providing safer guidance than a simple Euclidean distance. Next, the repulsive field ğ‘ˆ rep prevents collisions and is defined as: 

ğ‘ˆ rep (x) =

ï£±ï£´ï£´ï£²ï£´ï£´ï£³ 

> 12

ğœ‰ 

 1  

> ğ‘‘ (x)

âˆ’ 1

> ğ‘‘ 0

2

, ğ‘‘ (x) â‰¤ ğ‘‘ 0,

0, ğ‘‘ (x) > ğ‘‘ 0,

(2) where ğ‘‘ (x) is the signed distance, ğœ‰ is a scaling factor, and 

ğ‘‘ 0 defines the influence range of obstacles. The final guidance field is the negative gradient of a combined potential, 

F = âˆ’âˆ‡ ğ‘ˆ, ğ‘ˆ (x) = ğ‘ˆ att (x) + ğ‘ˆ rep (x), (3) which is then queried at the locations of different body parts, yielding field vectors F(xğ‘˜ ) for each body part pğ‘˜ . A 2D visualization of our APF is illustrated in Figure. 3 (a). While APF method typically models robots as a single rigid body, its direct application to multi-jointed humanoid robots could lead to conflicts between body parts. For instance, when the robot faces an obstacle directly ahead, it must decide whether to move left or right. The potential fields on the left and right sides of the body direct it toward opposite paths. In a symmetrical configuration, these vectors cancel each other out, leading to a multi-modal dilemma where the robot becomes trapped in a local minimum or exhibits oscillatory behavior. To address this challenge, we propose a priority-weighting scheme that prioritizes the in-fluence of certain body parts over others according to their contribution to the task. 

Priority-weighting. Instead of treating all body parts equally, our priority-weighting scheme adjusts the influence of each body part based on its role in the overall motion. To establish coherent global guidance, we assign a higher priority to the root body part (e.g., pelvis) since it plays a central role in maintaining stability and direction: 

ğ‘¤ 0 (proot ) = 1, ğ‘¤ 0 (pothers ) = 0.5. (4) Furthermore, some body parts are more critical in avoiding obstacles, particularly those closer to potential collisions. To account for this, we define a dynamic collision-urgency weight based on the signed distance ğ‘‘ (xğ‘˜ ) and the Cartesian velocity vğ‘˜ of body part pğ‘˜ , with a scaling factor ğœ† :

ğ‘¤ 1 (pğ‘˜ ) = ğœ† max (âˆ’âˆ‡ ğ‘‘ (xğ‘˜ ) Â· vğ‘˜ , 0.5) exp   âˆ’ ğ‘‘ (xğ‘˜ ). (5) The resulting HumanoidPF is defined as Fğ» = ğ‘¤ 0 ğ‘¤ 1 F 

> âˆ¥Fâˆ¥

.This scheme attenuates conflicting influences and promotes coordinated whole-body control. In particular, minute asym-metries in the spatial configuration are selectively amplified, thus seamlessly resolving the multi-modal dilemma. 

2) Traversal skill learning with HumanoidPF 

HumanoidPF for policy observation. To better inform RL policies about humanoid-obstacle relationships, we lever-age HumanoidPF to construct a compact, task-relevant visual observation. It is sampled at ğ¾ = 13 body parts, 

ğ‘‚ğµğ‘† ğ¹ğ‘–ğ‘’ğ‘™ğ‘‘ = {Fğ» (xğ‘˜ ) | xğ‘˜ }ğ¾ ğ‘˜ =1, (6) where each Fğ» (xğ‘˜ ) encodes the local directional guidance induced by obstacles and the target at body part ğ‘˜ , indicating collision-free motion. Sampling these fields at key body parts specifies how the humanoid should steer its body through the environment, allowing the policy to reason about traversal decisions rather than implicit inference from raw visual data. We empirically validate this in Section IV-A. HumanoidPF for observation further mitigates the percep-tual sim-to-real gap by representing the environment as a continuous, spatially aggregated field, which functions like a low-pass perceptual filter. Unlike raw sensor representations that retain fine-grained geometric details and are sensitive to small local perturbations, the field formulation suppresses isolated noise while preserving the dominant spatial gradients relevant to the traversal task. This ensures that minor geomet-ric variations do not significantly affect control during real-world deployment, as is empirically validated in Section IV-C 

HumanoidPF for policy reward. To streamline reward engineering, we employ HumanoidPF to induce anticipatory and dense guidance that generalizes across diverse environ-ments. At each time step, HumanoidPF encodes a distribution of preferred motion directions, and the policy is optimized to produce actions that align with this distribution, thus fostering safe and dexterous collision-avoidance behaviors. The von Misesâ€“Fisher (vMF) distribution is used to model directional preferences ğ (x) âˆˆ R3 on the unit sphere and allows the strength of this preference to be controlled by a single concentration parameter ğœ… (x) âˆˆ R:

ğ‘ ( Ë†v | ğ (x), ğœ… (x)) = ğ¶ ğ‘‘ (ğœ… ) exp  ğœ… (x) ğ (x)âŠ¤ Â· Ë†v, (7) where Ë†v is the motion direction of a humanoid body part, 

ğ¶ ğ‘‘ (ğœ… ) is the normalization function. 

ğ (x) and ğœ… (x) is directly derived from HumanoidPF: 

ğ (x) = Fğ» (x)âˆ¥Fğ» (x)âˆ¥ , ğœ… (x) = ğœ… max âˆ¥Fğ» (x)âˆ¥ , (8) where ğœ… max is a scaling factor. The body part with higher priority receives a field vector Fğ» (x) with larger magnitude; accordingly, ğœ… (x) increases to enforce stricter alignment with 

ğ (x) , and vice versa for lower-priority parts. This priority-aware concentration design promotes coordinated whole-body motion while improving collision-avoidance behavior, as illustrated in Figure 3 (b). During policy training, let the motion direction of the ğ‘˜ -th body part be Ë†vğ‘˜ = vğ‘˜ /âˆ¥ vğ‘˜ âˆ¥, the associated prior direction be Fig. 4: Collision-free humanoid traversal in both simulation and the real world. (a) Humanoid traversal behaviors on eight representative test scene types; (b) traversal behaviors in procedurally generated cluttered environments; (c) real-world â€œhurdle-crouchâ€ scenario, validating sim-to-real transfer in a cluttered indoor setting; (d) robustness under dynamic disturbances, where simple object movements (blue arrows) are introduced during traversal. 

ğ ğ‘˜ = ğ (xğ‘˜ ) and concentration parameter be ğœ… ğ‘˜ = ğœ… (xğ‘˜ ). As-suming independence among joints, the whole-body motion prior and log-likelihood reward are expressed as: 

ğ‘ ( Ë†v1: ğ¾ | x1: ğ¾ , Fğ» ) =

> ğ¾

Ã–

> ğ‘˜ =1

ğ¶ ğ‘‘ (ğœ… ğ‘˜ ) exp  ğœ… ğ‘˜ ğ âŠ¤ 

> ğ‘˜

Â· Ë†vğ‘˜ 

, (9) 

ğ‘… ğ¹ğ‘–ğ‘’ğ‘™ğ‘‘ =

> ğ¾

âˆ‘ï¸ 

> ğ‘˜ =1

h

log ğ¶ ğ‘‘ (ğœ… ğ‘˜ ) + ğœ… ğ‘˜ ğ âŠ¤ 

> ğ‘˜

Â· Ë†vğ‘˜ 

i

. (10) This reward formulation exhibits strong cross-scene gener-alization without requiring manual tuning, thereby enabling an automated training pipeline that scales effectively across diverse environments. 

B. Scalable training in diverse and challenging scenes 

For general practical use, the humanoid needs to handle diverse scenes within a single unified policy. It needs the policy trained with a sufficiently large and challenging indoor scene dataset to enable generalization in real-world cluttered scenes. Therefore, we propose a hybrid scene generation method in Section III-B.1. It incorporates crops of realistic 3D indoor scenes for structural realism, and procedurally synthesized obstacles to enrich highly challenging clutter configurations. In addition, even with HumanoidPF, directly learning a single policy across all scenes remains challenging due to the low sample efficiency of RL. We therefore adopt a specialist-to-generalist training strategy inspired by [36], [37], described in Section III-B.2. 

1) Hybrid scene generation 

We observe that highly challenging obstacle layouts constitute merely a long-tail subset in most existing datasets [38]â€“[40], since typical indoor scenes feature or-derly object arrangements and clearly delineated walkable regions. Simply scaling up the dataset does not alleviate this problem. Therefore, we propose a novel hybrid scene generation scheme that enriches realistic 3D indoor datasets with procedurally synthesized â€extremeâ€ obstacles, where full-spatial constraints are jointly present. 

Crops of realistic 3D indoor scenes. For generalization to intricate and realistic indoor environments, we adopt the 3D-FRONT [38] dataset, containing structurally realistic scenes with large-scale high-quality furniture objects. We selectively crop and filter scene blocks for policy training. Specifically, we first project all furniture onto the ground and erode the resulting planar walkable regions with a radius of 0.1 m to account for clearance. Within the remaining walkable regions, we randomly sample a start location and crop a 5 m Ã— 5 m block centered at this position. During training, the goal location will be randomly sampled on a circle with a radius of 2 m around the start. We initially train specialist policies on all such cropped scenes and subsequently identify scenes with low traversal success rates. Scenes that are empirically found to be non-traversable are manually filtered out. 

Procedurally generated obstacles. To supplement crops of 3D-FRONT with more challenging and cluttered envi-ronments, we procedurally generate obstacles that impose full-spatial (simultaneous ground, lateral, and overhead) con-straints, deliberately targeting highly restrictive scenarios. Specifically, we place boxes with varying positions, dimen-sions, and orientations that may extend upward from the floor, descend from the ceiling, and be placed in close proximity to form narrow traversal passages. To break structural regularity and enhance geometric real-ism, we apply random SO (3) rotations and 2D Perlin noise to each box. The resulting artifacts, such as spiky surfaces or non-manifold regions, are mitigated via 3D morpholog-ical closing and opening at the voxel level before mesh conversion. Visualizations of the robot traversing generated obstacles are shown in Figure 2 and Figure 4 (b). To support curriculum learning during policy training, we use a layout-agnostic difficulty factor to control obstacle complexity, such as the number and size of boxes. As the difficulty increases, the policy progressively acquires robust traversal skills under increasingly challenging configurations. Hurdle-Crouch Side-Hurdle-Crouch Side-Hurdle Side-Crouch                                                                                                                                                                                                      

> SR(%) â†‘DE(m) â†“SR(%) â†‘DE(m) â†“SR(%) â†‘DE(m) â†“SR(%) â†‘DE(m) â†“
> ASTraversal 28.1 Â±10.4 1.11 Â±0.78 0.5 Â±0.5 1.06 Â±0.39 37.1 Â±3.1 0.54 Â±0.32 56.0 Â±9.9 0.48 Â±0.05
> Humanoid Parkour 33.3 Â±6.1 1.16 Â±0.63 0.4 Â±0.3 1.49 Â±0.04 45.1 Â±4.5 0.62 Â±0.39 64.4 Â±19.3 0.56 Â±0.16
> Ours w/o ğ‘‚ğµğ‘† ğ¹ğ‘–ğ‘’ğ‘™ğ‘‘ 77.8 Â±5.4 0.33 Â±0.23 53.7 Â±9.9 0.59 Â±0.08 60.4 Â±9.6 0.53 Â±0.68 90.1 Â±5.3 0.19 Â±0.35
> Ours w/o ğ‘… ğ¹ğ‘–ğ‘’ğ‘™ğ‘‘ 21.9 Â±15.8 1.27 Â±0.71 0.0 Â±0.0 1.57 Â±0.003 71.4 Â±9.9 0.5 Â±0.34 80.3 Â±15.4 0.23 Â±0.06
> Ours 93.9 Â±2.7 0.08 Â±0.16 86.6 Â±5.2 0.2 Â±0.32 95.4 Â±3.9 0.06 Â±0.34 96.9 Â±2.1 0.05 Â±0.09
> Hurdle-Pass Crouch-Pass Side-Pass Multi-Hurdle
> SR(%) â†‘DE(m) â†“SR(%) â†‘DE(m) â†“SR(%) â†‘DE(m) â†“SR(%) â†‘DE(m) â†“
> ASTraversal 75.9 Â±6.8 0.66 Â±0.3 41.3 Â±5.3 0.9 Â±1.04 55.2 Â±8.5 0.78 Â±0.87 82.1 Â±8.7 0.26 Â±0.43
> Humanoid Parkour 84.3 Â±8.0 0.32 Â±0.18 48.1 Â±3.3 1.34 Â±0.18 41.3 Â±2.5 0.91 Â±0.34 88.7 Â±2.6 0.23 Â±0.35
> Ours w/o ğ‘‚ğµğ‘† ğ¹ğ‘–ğ‘’ğ‘™ğ‘‘ 92.3 Â±4.9 0.1 Â±0.15 96.8 Â±5.0 0.07 Â±0.3 95.2 Â±4.4 0.07 Â±0.22 90.5 Â±3.5 0.09 Â±0.11
> Ours w/o ğ‘… ğ¹ğ‘–ğ‘’ğ‘™ğ‘‘ 90.7 Â±7.5 0.12 Â±0.37 95.9 Â±5.0 0.08 Â±0.24 28.0 Â±18.3 1.07 Â±0.56 88.3 Â±14.1 0.23 Â±0.5
> Ours 96.9 Â±5.5 0.06 Â±0.15 97.5 Â±4.3 0.05 Â±0.09 97.3 Â±3.2 0.04 Â±0.15 95.0 Â±4.9 0.06 Â±0.1

TABLE II: Validation of HumanoidPF for skill learning. To better characterize the performance of our method under diverse obstacle layouts, we design 8 distinct scene types for evaluation and ablation studies. 

2) Specialist-to-generalist training 

We construct an automated and parallel specialist-to-generalist training pipeline. We first conduct large-scale training of specialist policies across diverse scenes via PPO [41]. The reward derived from HumanoidPF is scene-general, enabling scalable training on 139 cropped 3D-FRONT scenes and 216 procedurally generated scenes. Each specialist is trained with 32,768 parallel environments and 5,000,000 episodes, with start and goal locations randomly sampled for each episode. Subsequently, a generalist policy is distilled using DAg-ger [36] from multiple specialists as teacher policies. Ded-icated specialists provide expert actions conditioned on current obstacle, enabling the generalist to acquire strong generalization capability across varying scenarios. To learn robust and stable traversal skills, both specialist and generalist policies are trained with sensor noise and force perturbations to simulate realistic collision-avoidance condi-tions. In addition, a curriculum with progressively increasing scene difficulty is employed to gradually enhance traversal performance and explore the limits of the policyâ€™s obstacle-avoidance capability. 

C. Real-world deployment: Click-and-Traverse 

For real-world deployment, we instantiate our method as a teleoperated loco-navigation system, termed Click-and-Traverse (CAT). The system integrates a LiDARâ€“inertial SLAM pipeline based on Fast-LIO2 [42] and OctoMap [43]. It maintains an up-to-date environment mapping and field construction, both operating at a frequency of 10 Hz. The policy queries the HumanoidPF at different body parts via self-localization and forward-kinematics. Users could specify a desired goal by simply clicking on a grid map, after which the humanoid autonomously navi-gates to the target while avoiding collisions. This interface removes the need for labor-intensive control modalities such as joysticks or motion capture, providing a lightweight and highly automated teleoperation solution. IV. E XPERIMENT 

In this section, we provide extensive experimental results in both the MuJoCo [44] simulator and the real world on Unitree G1 humanoid robot. The experiments aim to address the following three questions:  

> â€¢

Q1 : Can HumanoidPF improve the performance of traversal in cluttered indoor scenes compared to existing methods?  

> â€¢

Q2 : Can our hybrid scene generation method help the policy generalize to unseen and challenging scenes?  

> â€¢

Q3 : Can the HumanoidPF for observation ğ‘‚ğµğ‘† ğ¹ğ‘–ğ‘’ğ‘™ğ‘‘ 

help the sim-to-real transfer? 

A. Validation of HumanoidPF for skill learning 

To address Q1 (Can HumanoidPF improve the perfor-mance of traversal in cluttered indoor scenes compared to existing methods? ), we compare the performance of our method against existing ones on traversing cluttered scenes. 

Experiment Setting. To systematically analyze perfor-mance under different obstacle layouts and geometric config-urations, we design eight distinct types of cluttered scenes for evaluation. All scenes used in this experiment are manually generated, each type exhibiting distinct characteristics and collectively covering a broad range of challenging obstacle configurations, with 10 scenes per type. We train and evaluate all methods on these generated scenes to compare their ability to traverse cluttered environments. Representative visualizations of the robot traversing each scene type are shown in Figure 4 (a). 

Experiment Metrics. We use the following metrics to evaluate the performance on traversing cluttered scenes:  

> â€¢

Success Rate (SR, %) records the percentage of suc-cessful traversal trials. A trial is considered successful if the robot reaches within 0.1 meters of the target location in 5 seconds without colliding with any obstacle.  

> â€¢

Distance Error (DE, m) is the averaged closest hor-izontal distance between the humanoid root and the target location in a traversal. Group Easy (SR%) Hard (SR%)                 

> Base 62.0 Â±23.4 1.2 Â±2.9
> Base + Syn-Partial-Easy 78.6 Â±12.2 12.3 Â±10.3
> Base + Syn-Full-Easy 83.1 Â±19.0 26.4 Â±5.8
> Base + Syn-Full-Hard 95.2 Â±6.1 66.7 Â±17.9

TABLE III: Validation of hybrid scene generation. Mean success rate (%) on easy and hard subsets for the four experiment groups (mean Â± std). 

Baselines. We choose the following methods and adapt them to fit our problem setting for a fair comparison:  

> â€¢

ASTraversal [13]: ASTraversal was originally proposed for quadrupeds. We re-implement its core multi-layer elevation maps and obstacle-avoidance reward for our humanoid framework.  

> â€¢

Humanoid Parkour [15]: The method enhances colli-sion penalties to better guide locomotion, but is limited to terrain modeling below the feet. To adapt it to our full-space traversal setting, we additionally provide overhead obstacle perception for fair comparison.  

> â€¢

Ours w/o ğ‘‚ğµğ‘† ğ¹ğ‘–ğ‘’ğ‘™ğ‘‘ : We replace the HumanoidPF in observation with multi-layer elevation maps as used in ASTraversal [13]. We adopt this baseline to evaluate the effectiveness of HumanoidPF for observation.  

> â€¢

Ours w/o ğ‘… ğ¹ğ‘–ğ‘’ğ‘™ğ‘‘ : We remove the HumanoidPF-guided reward. Instead, we use a basic collision-penalty reward commonly used in collision-avoidance tasks [15]. We adopt this baseline to validate HumanoidPF for reward. 

Experiment Results. Results are summarized in Table II. Our method consistently achieves the best performance across all types of test cases, demonstrating its strong traversal capability in cluttered scenes. In contrast, both Humanoid Parkour and ASTraversal only achieve compet-itive performance in relatively simple terrains. Nevertheless, our approach exhibits low variance over multiple trials, indicating high robustness and stability of the learned policy. 

B. Validation of hybrid scene generation 

To address Q2 (Can our hybrid scene generation method help the policy generalize to unseen and challenging scenes? ), We evaluate and compare the zero-shot scene generalization ability of the traversal policies trained with different scene datasets. 

Experiment Setting. We collect 30 artist-designed indoor scenes that were not included in the training dataset. These scenes are categorized according to obstacle density into 15 easy and 15 hard cases. We test the policies trained with different datasets in these unseen scenes and compare their zero-shot transfer performance. 

Experiment Metrics. We use the Success Rate (SR, %) 

metric as mentioned in Section IV-A. 

Baselines. We choose the following methods as baselines:  

> â€¢

Base: We use 3D-FRONT scenes only.  

> â€¢

Base + Syn-Partial-Easy: Base combined with a subset of moderate-difficulty ( â‰¤ 0.6) synthesized scenes.  

> â€¢

Base + Syn-Full-Easy: Base combined with the full set of moderate-difficulty ( â‰¤ 0.6) synthesized scenes.                     

> Real-world Crouch-Hurdle-Side-Crouch-Exteroception Pass Pass Pass Hurdle
> Voxel Grids 1/5 3/5 2/5 2/5 Elevation Maps 3/5 3/5 1/5 2/5 HumanoidPF (Ours) 4/5 5/5 5/5 4/5

TABLE IV: Validation of HumanoidPF for real world transfer. Success rate on four challenging real-world scenes.  

> â€¢

Base + Syn-Full-Hard: Base combined with the full set of high-difficulty ( 0.4 âˆ¼ 1.0) synthesized scenes. 

Experiment Results The results shown in Table III confirm that procedural obstacle generation is crucial to enhance generalization, as it systematically scales both the volume and the difficulty of training data. Despite significant performance improvement from the expansion of obstacle diversity, saturation in gains can be observed once common layout patterns are sufficiently learned. The key breakthrough emerges from training in scenes with novel complexities and tighter constraints, which induce the policy to develop the superior capabilities necessary for complex terrains. 

C. Validation of HumanoidPF for real world transfer 

To address Q3 (Can the HumanoidPF for observation 

ğ‘‚ğµğ‘† ğ¹ğ‘–ğ‘’ğ‘™ğ‘‘ help the sim-to-real transfer? ), we compare the traversal capability of our method with other perceptual representations under real-world conditions. 

Experiment Setting. We construct a set of representa-tive cluttered indoor traversal scenarios in the real world, covering crouching under low-hanging obstacles, hurdling over ground objects, and negotiating narrow-side passages. These scenarios are deliberately designed to stress perceptual reliability by evaluating whether the learned policy could remain collision-free traversal under real-world conditions. 

Experiment Metrics. We use the Success Rate (SR) 

metric as mentioned in Section IV-A. 

Baselines. We distill the same specialists to two different perceptual representation as baselines:  

> â€¢

Voxel Grids: Distilling to voxel-based visuomotor pol-icy.  

> â€¢

Multi-layer Elevation Maps: Distilling to two-layer-elevation visuomotor policy. 

Experiment Results. Results are summarized in Ta-ble IV. Our HumanoidPF consistently outperforms voxel-based approaches across diverse environments. For example, on hurdle terrains, the voxel-based method often exhibits instability because it is sensitive to fine-grained geometric details of obstacles and to noise in task-irrelevant regions. In contrast, HumanoidPF remains largely unaffected by such disturbances and shows behavior that aligns more closely with simulation, further confirming its robustness in sim-to-real transfer. Qualitative results of our method are shown in Figure 1 and Figure 4. V. C ONCLUSION 

In this work, we address collision-free humanoid traver-sal in cluttered indoor scenes. We introduce HumanoidPF, an informative representation to encode humanoidâ€“obstacle relationships for RL-based traversal skill learning, advancing toward real-world domestic humanoid robot application. De-spite these advances, several limitations remain. Our current framework does not yet exploit contact-rich interactions, such as leaning on obstacles or stepping onto support surfaces, and generalization to entirely unseen, highly un-structured, and extremely cluttered scenes remains an open challenge. REFERENCES [1] R. Grandia, F. Jenelten, S. Yang, F. Farshidian, and M. Hutter, â€œPerceptive locomotion through nonlinear model-predictive control,â€ 

IEEE Transactions on Robotics , vol. 39, no. 5, pp. 3402â€“3421, 2023. [2] J. Lee, J. Hwangbo, L. Wellhausen, V. Koltun, and M. Hutter, â€œLearning quadrupedal locomotion over challenging terrain,â€ Science robotics , vol. 5, no. 47, p. eabc5986, 2020. [3] C. Zhang, N. Rudin, D. Hoeller, and M. Hutter, â€œLearning agile loco-motion on risky terrains,â€ in 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) . IEEE, 2024, pp. 11 864â€“ 11 871. [4] X. Cheng, K. Shi, A. Agarwal, and D. Pathak, â€œExtreme parkour with legged robots,â€ in 2024 IEEE International Conference on Robotics and Automation (ICRA) . IEEE, 2024, pp. 11 443â€“11 450. [5] T. Miki, J. Lee, J. Hwangbo, L. Wellhausen, V. Koltun, and M. Hutter, â€œLearning robust perceptive locomotion for quadrupedal robots in the wild,â€ Science robotics , vol. 7, no. 62, p. eabk2822, 2022. [6] J. Lee, M. Bjelonic, A. Reske, L. Wellhausen, T. Miki, and M. Hutter, â€œLearning robust autonomous navigation and locomotion for wheeled-legged robots,â€ Science Robotics , vol. 9, no. 89, p. eadi9641, 2024. [7] N. Rudin, D. Hoeller, M. Bjelonic, and M. Hutter, â€œAdvanced skills by learning locomotion and local navigation end-to-end,â€ in 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) . IEEE, 2022, pp. 2497â€“2503. [8] Z. Wang, T. Ma, Y. Jia, X. Yang, J. Zhou, W. Ouyang, Q. Zhang, and J. Liang, â€œOmni-perception: Omnidirectional collision avoidance for legged locomotion in dynamic environments,â€ arXiv preprint arXiv:2505.19214 , 2025. [9] D. Hoeller, N. Rudin, D. Sako, and M. Hutter, â€œAnymal parkour: Learning agile navigation for quadrupedal robots,â€ Science Robotics ,vol. 9, no. 88, p. eadi7566, 2024. [10] T. Miki, J. Lee, L. Wellhausen, and M. Hutter, â€œLearning to walk in confined spaces using 3d representation,â€ in 2024 IEEE International Conference on Robotics and Automation (ICRA) . IEEE, 2024, pp. 8649â€“8656. [11] Z. Zhuang, Z. Fu, J. Wang, C. Atkeson, S. Schwertfeger, C. Finn, and H. Zhao, â€œRobot parkour learning,â€ arXiv preprint arXiv:2309.05665 ,2023. [12] N. Rudin, J. He, J. Aurand, and M. Hutter, â€œParkour in the wild: Learn-ing a general and extensible agile locomotion policy using multi-expert distillation and rl fine-tuning,â€ arXiv preprint arXiv:2505.11164 , 2025. [13] Y. Chen, J. Ma, Z. Luo, Y. Han, Y. Dong, B. Xu, and P. Lu, â€œLearning autonomous and safe quadruped traversal of complex terrains using multi-layer elevation maps,â€ IEEE Robotics and Automation Letters ,2025. [14] Z. Li, J. Zeng, S. Chen, and K. Sreenath, â€œAutonomous navigation of underactuated bipedal robots in height-constrained environments,â€ 

The International Journal of Robotics Research , vol. 42, no. 8, pp. 565â€“585, 2023. [15] Z. Zhuang, S. Yao, and H. Zhao, â€œHumanoid parkour learning,â€ arXiv preprint arXiv:2406.10759 , 2024. [16] J. He, C. Zhang, F. Jenelten, R. Grandia, M. BÂ¨ acher, and M. Hutter, â€œAttention-based map encoding for learning generalized legged loco-motion,â€ Science Robotics , vol. 10, no. 105, p. eadv3604, 2025. [17] J. Sun, G. Han, P. Sun, W. Zhao, J. Cao, J. Wang, Y. Guo, and Q. Zhang, â€œDpl: Depth-only perceptive humanoid locomotion via realistic depth synthesis and cross-attention terrain reconstruction,â€ 

arXiv preprint arXiv:2510.07152 , 2025. [18] J. Long, J. Ren, M. Shi, Z. Wang, T. Huang, P. Luo, and J. Pang, â€œLearning humanoid locomotion with perceptive internal model,â€ in 

2025 IEEE International Conference on Robotics and Automation (ICRA) . IEEE, 2025, pp. 9997â€“10 003. [19] J. Ren, T. Huang, H. Wang, Z. Wang, Q. Ben, J. Long, Y. Yang, J. Pang, and P. Luo, â€œVb-com: Learning vision-blind composite humanoid locomotion against deficient perception,â€ arXiv preprint arXiv:2502.14814 , 2025. [20] T. Huang, R. Xu, Y. Wang, W. Gao, and S. Zhang, â€œTraversing narrow paths: A two-stage reinforcement learning framework for robust and safe humanoid walking,â€ arXiv preprint arXiv:2508.20661 , 2025. [21] H. Wang, Z. Wang, J. Ren, Q. Ben, T. Huang, W. Zhang, and J. Pang, â€œBeamdojo: Learning agile humanoid locomotion on sparse footholds,â€ arXiv preprint arXiv:2502.10363 , 2025. [22] W. Sun, B. Cao, L. Chen, Y. Su, Y. Liu, Z. Xie, and H. Liu, â€œLearning perceptive humanoid locomotion over challenging terrain,â€ 

arXiv preprint arXiv:2503.00692 , 2025. [23] Q. Ben, B. Xu, K. Li, F. Jia, W. Zhang, J. Wang, J. Wang, D. Lin, and J. Pang, â€œGallant: Voxel grid-based humanoid locomotion and local-navigation across 3d constrained terrains,â€ arXiv preprint arXiv:2511.14625 , 2025. [24] Z. Zhang, J. Guo, C. Chen, J. Wang, C. Lin, Y. Lian, H. Xue, Z. Wang, M. Liu, J. Lyu, et al. , â€œTrack any motions under any disturbances,â€ 

arXiv preprint arXiv:2509.13833 , 2025. [25] O. Khatib, â€œReal-time obstacle avoidance for manipulators and mobile robots,â€ The international journal of robotics research , vol. 5, no. 1, pp. 90â€“98, 1986. [26] Z. Wu, J. Dai, B. Jiang, and H. R. Karimi, â€œRobot path planning based on artificial potential field with deterministic annealing,â€ ISA transactions , vol. 138, pp. 74â€“87, 2023. [27] Y. K. Hwang, N. Ahuja, et al. , â€œA potential field approach to path planning.â€ IEEE transactions on robotics and automation , vol. 8, no. 1, pp. 23â€“32, 1992. [28] S. S. Ge and Y. J. Cui, â€œDynamic motion planning for mobile robots using potential field method,â€ Autonomous robots , vol. 13, no. 3, pp. 207â€“222, 2002. [29] Y. Gong, R. Laha, and L. Figueredo, â€œGeopf: Infusing geometry into potential fields for reactive planning in non-trivial environments,â€ 

arXiv preprint arXiv:2505.19688 , 2025. [30] M. Ginesi, D. Meli, A. Roberti, N. Sansonetto, and P. Fiorini, â€œDynamic movement primitives: Volumetric obstacle avoidance using dynamic potential functions,â€ Journal of Intelligent & Robotic Systems ,vol. 101, no. 4, p. 79, 2021. [31] Y. Chen, L. Chen, J. Ding, and Y. Liu, â€œResearch on real-time obstacle avoidance motion planning of industrial robotic arm based on artificial potential field method in joint space,â€ Applied Sciences , vol. 13, no. 12, p. 6973, 2023. [32] H. Igarashi, T. Machida, F. Harashima, and M. Kakikura, â€œFree gait for quadruped robots with posture control,â€ in 9th IEEE International Workshop on Advanced Motion Control, 2006. IEEE, 2006, pp. 433â€“ 438. [33] H. Igarashi and M. Kakikura, â€œPath and posture planning for walking robots by artificial potential field method,â€ in IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRAâ€™04. 2004 , vol. 3. IEEE, 2004, pp. 2165â€“2170. [34] F. Zhuo, W. Jia, S. Ma, J. Yuan, and Y. Sun, â€œA variable artificial potential field method for gait generation of quadruped robot,â€ in 

2021 IEEE International Conference on Mechatronics and Automation (ICMA) . IEEE, 2021, pp. 1176â€“1181. [35] Y. A. Voeurn and M. I. Raza, â€œMotion planning of quadruped robot using potential field,â€ in 2021 International Conferenceâ€ Nonlinearity, Information and Roboticsâ€(NIR) . IEEE, 2021, pp. 1â€“6. [36] S. Ross, G. Gordon, and D. Bagnell, â€œA reduction of imitation learning and structured prediction to no-regret online learning,â€ in Proceedings of the fourteenth international conference on artificial intelligence and statistics . JMLR Workshop and Conference Proceedings, 2011, pp. 627â€“635. [37] Z. Zhang, C. Chen, H. Xue, J. Wang, S. Liang, Y. Liu, Z. Zhang, H. Wang, and L. Yi, â€œUnleashing humanoid reaching potential via real-world-ready skill space,â€ arXiv preprint arXiv:2505.10918 , 2025. [38] H. Fu, B. Cai, L. Gao, L.-X. Zhang, J. Wang, C. Li, Q. Zeng, C. Sun, R. Jia, B. Zhao, et al. , â€œ3d-front: 3d furnished rooms with layouts and semantics,â€ in Proceedings of the IEEE/CVF International Conference on Computer Vision , 2021, pp. 10 933â€“10 942. [39] M. Deitke, E. VanderBilt, A. Herrasti, L. Weihs, K. Ehsani, J. Salvador, W. Han, E. Kolve, A. Kembhavi, and R. Mottaghi, â€œProcthor: Large-scale embodied ai using procedural generation,â€ Advances in Neural Information Processing Systems , vol. 35, pp. 5982â€“5994, 2022. [40] S. K. Ramakrishnan, A. Gokaslan, E. Wijmans, O. Maksymets, A. Clegg, J. Turner, E. Undersander, W. Galuba, A. Westbury, A. X. Chang, et al. , â€œHabitat-matterport 3d dataset (hm3d): 1000 large-scale 3d environments for embodied ai,â€ arXiv preprint arXiv:2109.08238 ,2021. [41] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, â€œProximal policy optimization algorithms,â€ arXiv preprint arXiv:1707.06347 , 2017. [42] W. Xu, Y. Cai, D. He, J. Lin, and F. Zhang, â€œFast-lio2: Fast direct lidar-inertial odometry,â€ 2021. [Online]. Available: https://arxiv.org/abs/2107.06829 [43] A. Hornung, K. M. Wurm, M. Bennewitz, C. Stachniss, and W. Burgard, â€œOctoMap: An efficient probabilistic 3D mapping framework based on octrees,â€ Autonomous Robots , 2013, software available at https://octomap.github.io. [Online]. Available: https: //octomap.github.io [44] E. Todorov, T. Erez, and Y. Tassa, â€œMujoco: A physics engine for model-based control,â€ in 2012 IEEE/RSJ international conference on intelligent robots and systems . IEEE, 2012, pp. 5026â€“5033.