# PAL*M: Property Attestation for Large Generative Models
# PAL*M：大型生成式模型的属性证明

**Authors**: Prach Chantasantitam, Adam Ilyas Caulfield, Vasisht Duddu, Lachlan J. Gunn, N. Asokan
**Date**: 2026-01-22
**PDF**: https://arxiv.org/pdf/2601.16199v1
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">query:大厂llm</span>
**Score**: 9.0
**Evidence**: framework for property attestation in large language models aligns with LLM evaluation query

---

## Abstract
Machine learning property attestations allow provers (e.g., model providers or owners) to attest properties of their models/datasets to verifiers (e.g., regulators, customers), enabling accountability towards regulations and policies. But, current approaches do not support generative models or large datasets. We present PAL*M, a property attestation framework for large generative models, illustrated using large language models. PAL*M defines properties across training and inference, leverages confidential virtual machines with security-aware GPUs for coverage of CPU-GPU operations, and proposes using incremental multiset hashing over memory-mapped datasets to efficiently track their integrity. We implement PAL*M on Intel TDX and NVIDIA H100, showing it is efficient, scalable, versatile, and secure.

## 摘要
机器学习属性证明允许证明者（如模型提供者或所有者）向验证者（如监管机构、客户）证明其模型或数据集的属性，从而实现对法规和政策的问责。然而，现有方法并不支持生成式模型或大型数据集。我们提出了 PAL*M，这是一个针对大型生成式模型的属性证明框架，并以大语言模型为例进行了演示。PAL*M 定义了贯穿训练和推理阶段的属性

---

## 论文详细总结（自动生成）

这是一份关于论文《PAL*M: Property Attestation for Large Generative Models》的结构化深入分析报告：

---

# 论文总结：PAL*M —— 大型生成式模型的属性证明框架

## 1. 核心问题与整体含义（研究动机和背景）
随着 AI 监管法规（如《欧盟 AI 法案》）的出现，模型提供者需要向监管机构或客户证明其模型和数据的合规性（如训练数据的来源、模型的准确性、推理过程的真实性）。
*   **核心挑战**：现有的机器学习属性证明（ML Property Attestation）方法（如 Laminator）主要针对小型分类器，无法扩展到大型生成式模型（如 LLM）。
*   **技术瓶颈**：
    1.  **大数据集问题**：LLM 数据集（如数百 GB）无法完全装入受信任执行环境（TEE）的内存，且训练时的随机采样破坏了传统的线性哈希完整性校验。
    2.  **异构计算**：LLM 依赖 CPU-GPU 协同，而现有的 TEE 证明多局限于 CPU。
    3.  **操作复杂性**：缺乏对微调、量化、对话会话等生成式特有操作的属性定义。

## 2. 方法论：核心思想与关键技术
PAL*M 提出了一个基于硬件 TEE 的属性证明框架，核心思想是在机密虚拟机（CVM）中执行 ML 操作，并利用硬件根信任生成不可篡改的证明。

*   **增量多重集哈希（Incremental Multiset Hashing, MSH）**：
    *   针对内存映射（Memory-mapped）的大型数据集，PAL*M 不再一次性读取整个文件，而是在随机采样记录时进行哈希。
    *   使用 `Mset-Mu-Hash` 算法，其结果与记录的读取顺序无关，确保了即使在随机采样下也能验证数据集的完整性。
*   **CPU-GPU 联合证明**：
    *   利用 **Intel TDX**（机密虚拟机）保护 CPU 侧逻辑，利用 **NVIDIA H100** 的机密计算模式保护 GPU 侧计算。
    *   通过将 GPU 的证明令牌（GPU att）嵌入到 CPU 的 TDREPORT 中，形成一个绑定了异构环境的统一证据。
*   **属性定义与协议流程**：
    *   定义了 8 种证明类型：预处理证明、分布证明、绑定证明、训练证明、优化证明（微调/量化）、评估证明、推理证明及会话推理证明。
    *   **流程**：发起者请求 -> PAL*M 在 TEE 中执行并测量输入/输出 -> 生成 TDREPORT -> 转换为 QUOTE（签名证据） -> 验证者核对。

## 3. 实验设计
*   **数据集**：
    *   **BookCorpus**（74M 小说）：用于训练、分布和预处理证明。
    *   **Alpaca**：用于指令微调证明。
    *   **MMLU & WMT14**：用于模型评估证明（多任务理解与翻译）。
    *   **CoQA**：用于推理和对话会话证明。
*   **模型对象**：GPT-2（训练）、Llama-3.1-8B、Gemma-3-4B、Phi-4-Mini（微调、评估、推理）。
*   **对比基准（Benchmark）**：
    *   **Baseline**：在相同的 Intel TDX 环境下运行，但不开启 PAL*M 的测量和证明功能。
    *   对比维度：总耗时、内存占用、测量开销、证明生成开销。

## 4. 资源与算力
*   **硬件配置**：
    *   **CPU**：Intel Xeon Silver 4514Y（支持 TDX）。
    *   **GPU**：NVIDIA H100 NVL (94GB)，开启机密计算模式。
    *   **内存**：512GB RAM（分配给 TD 虚拟机 128GB）。
*   **算力规模**：实验涵盖了从 4B 到 8B 参数规模的模型。训练和微调实验的时长以“分钟”计（如 Llama-3.1-8B 微调约 269 分钟）。

## 5. 实验数量与充分性
*   **实验覆盖面**：论文针对定义的 8 种属性证明分别进行了实验，涵盖了从数据准备到模型部署的全生命周期。
*   **多样性**：测试了三种不同的主流 LLM 架构（Llama, Gemma, Phi），并对比了“全内存加载”与“内存映射”两种数据处理策略。
*   **充分性评价**：实验设计较为充分。每组实验运行 5 次取平均值，涵盖了性能开销分析和安全性分析（对抗模型测试）。虽然模型参数量最高仅为 8B（受限于单卡 H100 显存），但已足以验证框架的有效性。

## 6. 主要结论与发现
*   **高效性**：在计算密集型任务（如训练、微调）中，PAL*M 的测量开销极低（**< 6%**）。
*   **内存映射的优势**：使用 MSH 处理内存映射数据集，相比全内存加载