# SAMTok: Representing Any Mask with Two Words
# SAMTok：用两个词表示任意掩码

**Authors**: Yikang Zhou, Tao Zhang, Dengxian Gong, Yuanzheng Wu, Ye Tian, Haochen Wang, Haobo Yuan, Jiacong Wang, Lu Qi, Hao Fei, Anran Wang, Zhuochen Wang, Yujing Wang, Cheng Chen, Shunping Ji, Xiangtai Li
**Date**: 2026-01-22
**PDF**: https://arxiv.org/pdf/2601.16093v1
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">keyword:RL</span> <span class="tag-label tag-pink">query:大厂llm</span>
**Score**: 7.0
**Evidence**: Uses reinforcement learning and QwenVL series LLMs for pixel-wise capabilities

---

## Abstract
Pixel-wise capabilities are essential for building interactive intelligent systems. However, pixel-wise multi-modal LLMs (MLLMs) remain difficult to scale due to complex region-level encoders, specialized segmentation decoders, and incompatible training objectives. To address these challenges, we present SAMTok, a discrete mask tokenizer that converts any region mask into two special tokens and reconstructs the mask using these tokens with high fidelity. By treating masks as new language tokens, SAMTok enables base MLLMs (such as the QwenVL series) to learn pixel-wise capabilities through standard next-token prediction and simple reinforcement learning, without architectural modifications and specialized loss design. SAMTok builds on SAM2 and is trained on 209M diverse masks using a mask encoder and residual vector quantizer to produce discrete, compact, and information-rich tokens. With 5M SAMTok-formatted mask understanding and generation data samples, QwenVL-SAMTok attains state-of-the-art or comparable results on region captioning, region VQA, grounded conversation, referring segmentation, scene graph parsing, and multi-round interactive segmentation. We further introduce a textual answer-matching reward that enables efficient reinforcement learning for mask generation, delivering substantial improvements on GRES and GCG benchmarks. Our results demonstrate a scalable and straightforward paradigm for equipping MLLMs with strong pixel-wise capabilities. Our code and models are available.

## 摘要
像素级能力对于构建交互式智能系统至关重要。然而，由于

---

## 速览摘要（自动生成）

**问题**：现有像素级多模态大模型架构复杂、难以扩展且训练目标不兼容。

**方法**：提出 SAMTok 离散掩码分词器，将任意掩码转化为两个特殊 Token。基于此，MLLM 无需修改架构即可