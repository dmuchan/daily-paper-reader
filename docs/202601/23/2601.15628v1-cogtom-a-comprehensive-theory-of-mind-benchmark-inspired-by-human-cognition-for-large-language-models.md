# CogToM: A Comprehensive Theory of Mind Benchmark inspired by Human Cognition for Large Language Models
# CogToM：受人类认知启发的大语言模型心理理论综合评测基准

**Authors**: Haibo Tong, Zeyang Yue, Feifei Zhao, Erliang Lin, Lu Jia, Ruolin Chen, Yinqian Sun, Qian Zhang, Yi Zeng
**Date**: 2026-01-22
**PDF**: https://arxiv.org/pdf/2601.15628v1
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">query:大厂llm</span>
**Score**: 9.0
**Evidence**: comprehensive benchmark for frontier LLMs like GPT and Qwen

---

## Abstract
Whether Large Language Models (LLMs) truly possess human-like Theory of Mind (ToM) capabilities has garnered increasing attention. However, existing benchmarks remain largely restricted to narrow paradigms like false belief tasks, failing to capture the full spectrum of human cognitive mechanisms. We introduce CogToM, a comprehensive, theoretically grounded benchmark comprising over 8000 bilingual instances across 46 paradigms, validated by 49 human annotator.A systematic evaluation of 22 representative models, including frontier models like GPT-5.1 and Qwen3-Max, reveals significant performance heterogeneities and highlights persistent bottlenecks in specific dimensions. Further analysis based on human cognitive patterns suggests potential divergences between LLM and human cognitive structures. CogToM offers a robust instrument and perspective for investigating the evolving cognitive boundaries of LLMs.

## 摘要
大语言模型（LLMs）是否真正具备类人的心理理论（ToM）能力已引起越来越多的关注

---

## 论文详细总结（自动生成）

这是一份关于论文《CogToM: A Comprehensive Theory of Mind Benchmark inspired by Human Cognition for Large Language Models》的结构化深入总结：

### 1. 论文的核心问题与整体含义（研究动机和背景）
*   **核心问题**：大语言模型（LLMs）是否真正具备类人的“心理理论”（Theory of Mind, ToM）能力，即推断他人心理状态（意图、信念、欲望等）的能力。
*   **研究动机**：
    *   **现有基准局限性**：现有的 ToM 评测（如错误信念任务 False Belief）过于单一，且容易被模型通过浅层模式匹配（Pattern Matching）破解。
    *   **认知深度不足**：现有基准缺乏心理学理论支撑，无法覆盖人类社交认知的全谱系。
    *   **机器与人差异**：需要一个更具辨别力的工具来揭示 LLM 与人类认知结构之间的潜在分歧。

### 2. 论文提出的方法论：CogToM 框架
*   **核心思想**：基于人类认知心理学（参考 ATOMS 框架），构建一个包含 46 种任务范式、覆盖 7 大认知维度的综合性评测基准。
*   **关键技术细节**：
    *   **七大维度**：情绪（Emotion）、欲望（Desire）、意图（Intention）、感知（Percept）、知识（Knowledge）、信念（Belief）、非字面意义理解（Non-literal）。
    *   **数据构建流水线（6 阶段）**：
        1.  **任务收集与适配**：从心理学文献中提取范式。
        2.  **专家编写规范**：制定结构化任务说明。
        3.  **LLM 自动扩展**：利用 GPT-5.1 生成初步场景和问题。
        4.  **初步审核**：专家轮流检查生成质量。
        5.  **双盲人工标注**：42 名研究生进行答案标注和质量评估。
        6.  **最终校验与翻译**：专家仲裁争议，并构建中英双语版本。
*   **数据规模**：共 8,513 个数据条目，每个条目包含场景描述、多项选择题及专家验证的答案。

### 3. 实验设计
*   **评测对象**：22 个代表性模型，涵盖从早期 Llama-2 到最前沿的 **GPT-5.1**、**Qwen3-Max**、**DeepSeek-v3** 等。
*   **评测设置**：
    *   **Zero-shot Vanilla Prompt**：直接输出选项。
    *   **抗偏置处理**：每个问题测试 5 次（4 次选项循环旋转 + 1 次随机打乱），取平均准确率。
*   **对比维度**：
    *   模型规模（Scaling Laws）的影响。
    *   中英双语表现差异。
    *   新旧任务范式的难度对比。
    *   模型表现与人类标注一致性（IAR）的相关性。

### 4. 资源与算力
*   **算力说明**：论文**未明确说明**具体的训练算力（如 GPU 型号或时长），因为该研究侧重于**评测基准的构建与推理评估**，而非模型训练。
*   **人力资源**：投入了 49 名人类专家/标注者（包括 6 名核心成员和 42 名哲学/AI 背景的研究生），每位标注者报酬为 30 美元。

### 5. 实验数量与充分性
*   **实验规模**：
    *   测试了 22 个模型，跨越了不同的发布时间线和参数规模。
    *   涵盖 46 个细分任务，总计超过 8,000 个实例。
*   **充分性与客观性**：
    *   **充分性**：实验不仅做了准确率排名，还深入分析了认知维度差异、人类发育里程碑对齐、以及莫拉维克悖论分析，实验非常充分。
    *   **客观性**：通过 5 次循环测试消除选项位置偏置，并引入双盲人工标注和专家仲裁，确保了 Benchmark 标签的客观性。

### 6. 论文的主要结论与发现
*   **性能演进**：模型 ToM 能力随时间及规模显著提升，前沿模型（Qwen3-Max, GPT-5.1）准确率已突破 80%。
*   **认知异质性**：LLM 在情绪、欲望理解上表现接近天花板，但在**感知（Percept）维度（如空间透视切换）表现极差**（中位数仅 20%）。
*   **莫拉维克悖论（Moravec’s Paradox）**：LLM 表现出“认知倒置”现象——它们能处理复杂的社会情感推理（人类晚期习得），却在基础的感官偏