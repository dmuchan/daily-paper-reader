# A Comprehensive Benchmark of Language Models on Unicode and Romanized Sinhala
# 针对 Unicode 和罗马化僧伽罗语的语言模型全面基准测试

**Authors**: Minuri Rajapakse, Ruvan Weerasinghe
**Date**: 2026-01-21
**PDF**: https://arxiv.org/pdf/2601.14958v1
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">query:大厂llm</span>
**Score**: 9.0
**Evidence**: Comprehensive benchmark of modern language models including Llama-3.1 and Mistral

---

## Abstract
The performance of Language Models (LMs) on lower-resource, morphologically rich languages like Sinhala remains under-explored, particularly for Romanized Sinhala, which is prevalent in digital communication. This paper presents a comprehensive benchmark of modern LMs on a diverse corpus of Unicode and Romanized Sinhala. We evaluate open-source models using perplexity, a measure of how well a model predicts a text, and leading closed-source models via a qualitative analysis of sentence completion. Our findings reveal that the Mistral-Nemo-Base-2407 model achieves the strongest predictive performance on Unicode text and the Mistral-7B-v0.3 model for Romanized text. The results also highlight the strong all-around performance of the Llama-3.1-8B model for both scripts. Furthermore, a significant performance disparity exists among closed-source models: Gemini-1.5-pro and DeepSeek excel at Unicode generation, whereas Claude-3.5-Sonnet is superior at handling Romanized text. These results provide an essential guide for practitioners selecting models for Sinhala-specific applications and highlight the critical role of training data in handling script variations.

## 摘要
语言模型（LM）在僧伽罗语等低资源、形态丰富语言上的表现仍有待深入探索，特别是对于在数字通信中盛行的罗马化僧伽罗语。本文针对 Unicode 和罗马化僧伽罗语的多样化语料库，提出了现代语言模型的全面基准测试。我们

---

## 论文详细总结（自动生成）

这篇论文对现代语言模型在僧伽罗语（Sinhala）上的表现进行了深入的基准测试，特别关注了官方 Unicode 脚本与社交媒体常用的罗马化（Romanized）脚本之间的差异。

以下是对该论文的结构化总结：

### 1. 核心问题与整体含义（研究动机和背景）
*   **核心问题**：僧伽罗语作为一种低资源、形态丰富的语言，在数字通信中存在“脚本双重性”——官方/文学使用 Unicode 脚本，而社交媒体/即时通讯则盛行罗马化脚本。
*   **研究动机**：现有的语言模型评估多集中于英语等高资源语言，或仅关注翻译任务（如 BLEU 分数），缺乏对僧伽罗语内在语言建模能力（如困惑度 Perplexity）的系统评估，尤其是对罗马化脚本的处理能力尚属空白。

### 2. 论文提出的方法论
*   **语料库构建**：从博客、YouTube 等多样化数字平台采集并整理了 1000 条僧伽罗语平行句子（包含 Unicode 和对应的罗马化版本）。
*   **代表性采样**：为了消除选择偏差，研究者使用 **LaBSE 句子嵌入**技术将句子向量化，随后应用 **K-Means 聚类**算法将 1000 条句子分为 200 个语义簇，从每个簇中心选取最接近的句子，构建出 200 条具有高度代表性的评估集。
*   **评估指标**：
    *   **开源模型**：使用**困惑度（Perplexity, PPL）**，衡量模型预测文本的准确性。
    *   **闭源模型**：由于无法获取概率分布，采用**定性分析**。由母语专家对模型生成的句子完成度进行评分（1-3 分制），维度包括**连贯性（Coherence）**和**语法/可读性（Grammar/Readability）**。

### 3. 实验设计
*   **数据集**：200 条精心挑选的 Unicode 与罗马化平行句子。
*   **对比方法（模型）**：
    *   **开源模型（13个）**：包括 Mistral-Nemo-Base-2407、Llama-3.1-8B、Mistral-7B-v0.3、Gemma 系列、Qwen2、Phi-4 等。
    *   **闭源模型（4个）**：GPT-4o、Claude-3.5-Sonnet、Gemini 1.5 Pro、DeepSeek。
*   **场景**：分别在纯 Unicode 环境和纯罗马化环境下测试模型的预测和生成能力。

### 4. 资源与算力
*   **文中说明**：论文**未明确提及**具体的训练算力（如 GPU 型号、数量或时长）。
*   **原因**：本研究属于**基准测试（Benchmarking）**性质，主要侧重于对现有预训练模型的推理评估，而非从头训练模型，因此算力消耗主要集中在推理阶段。

### 5. 实验数量与充分性
*   **实验规模**：
    *   定量实验：针对 13 个开源模型在 200 条句子上计算 PPL。
    *   定性实验：针对 4 个闭源模型在 50 条句子的子集上进行人工评分。
*   **充分性评价**：
    *   **客观性**：通过 K-Means 聚类确保了样本的语义覆盖面，比随机选取更科学。
    *   **局限性**：200 条句子的样本量对于全面覆盖僧伽罗语复杂的形态变化和罗马化拼写变体来说仍显不足。

### 6. 论文的主要结论与发现
*   **最佳模型**：
    *   **Unicode 脚本**：**Mistral-Nemo-Base-2407** 表现最强（PPL 2.19）；闭源模型中 **Gemini-1.5-pro** 和 **DeepSeek** 生成质量最高。
    *   **罗马化脚本**：**Mistral-7B-v0.3** 预测最准（PPL 74.76）；闭源模型中 **Claude-3.5-Sonnet** 显著优于其他模型。
    *   **全能表现**：**Llama-3.1-8B** 在两种脚本下均表现稳健，是兼顾效率与效果的理想选择。
*   **关键发现**：
    *   **模型大小不等于性能**：8B 的 Llama-3.1 在 Unicode 上的表现优于 14B 的 Phi-4，说明分词效率和架构优化更关键。
    *   **语法弱点**：大多数模型在僧伽罗语的**主谓一致**和形态变化上存在困难。
    *   **训练数据决定脚本偏好**：模型在不同脚本上的表现差异反映了其预训练语料库中 Unicode 与罗马化文本的比例差异。

### 7. 优点
*   **填补空白**：这是首个针对僧伽罗语双脚本（尤其是罗马化脚本）的现代语言模型全面基准测试。
*   **采样科学**：引入 LaBSE 和 K-Means 聚类进行样本筛选，增强了评估集的代表性和公平性。
*   **实用性强**：为开发者在选择针对僧伽罗语应用的底层模型时提供了直接的参考依据。

### 8. 不足与局限
*   **样本量较小**：