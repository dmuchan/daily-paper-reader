# Benchmarking Large Language Models for ABAP Code Generation: An Empirical Study on Iterative Improvement by Compiler Feedback
# ABAP代码生成的大语言模型基准测试：基于编译器反馈迭代改进的实证研究

**Authors**: Stephan Wallraven, Tim Köhne, Hartmut Westenberger, Andreas Moser
**Date**: 2026-01-21
**PDF**: https://arxiv.org/pdf/2601.15188v1
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">query:大厂llm</span>
**Score**: 8.0
**Evidence**: benchmarking large language models for code generation and iterative improvement

---

## Abstract
This work investigates the performance of Large Language Models (LLMs) in generating ABAP code. Despite successful applications of generative AI in many programming languages, there are hardly any systematic analyses of ABAP code generation to date. The aim of the study is to empirically analyze to what extent various LLMs can generate syntactically correct and functional ABAP code, how effectively they use compiler feedback for iterative improvement, and which task types pose special challenges. For this purpose, a benchmark with 180 tasks is conducted, consisting of adapted HumanEval tasks and practical SAP scenarios. The results show significant performance differences between the models: more powerful LLMs achieve success rates of around 75% after several iterations and benefit greatly from compiler feedback, while smaller models perform significantly weaker. Overall, the study highlights the high potential of powerful LLMs for ABAP development processes, especially in iterative error correction.

## 摘要
本研究调查了大语言模型（LLMs）在生成ABAP代码方面的性能。尽管生成式人工智能已在多种编程语言中得到成功应用，但迄今为止，针对ABAP代码生成的系统性分析仍寥寥无几。本研究旨在实证分析各种LLM在多大程度上能够生成语法正确且功能完备的ABAP代码，它们利用编译器反馈进行迭代改进的效果如何，以及哪些任务类型构成了特殊挑战。为此，研究开展了一项包含180个任务的基准测试，其中包括改编自HumanEval的任务以及实际的SAP应用场景。结果显示，不同模型之间存在显著的性能差异：性能更强的LLM在经过多次迭代后成功率可达75%左右，并能从编译器反馈中获益匪浅，而较小规模的模型表现则明显较弱。总体而言，本研究强调了强大的LLM在ABAP开发流程中的巨大潜力，特别是在迭代错误修复方面。

---

## 论文详细总结（自动生成）

这是一份关于论文《Benchmarking Large Language Models for ABAP Code Generation: An Empirical Study on Iterative Improvement by Compiler Feedback》的结构化深入分析报告：

---

### 1. 核心问题与整体含义（研究动机和背景）
*   **研究背景**：ABAP（高级商业应用编程语言）是 SAP 生态系统的核心，具有极高的商业价值。然而，与 Python 或 Java 不同，ABAP 是一种**“低资源语言”**（Low-resource language），公开的训练数据稀缺，导致通用大模型在生成 ABAP 代码时语法错误率高、遵循最佳实践能力差。
*   **核心问题**：目前缺乏针对 ABAP 代码生成的系统性基准测试。本研究旨在填补这一空白，探索 LLM 在 ABAP 领域的真实水平，特别是**“编译器反馈（Compiler Feedback）”**在迭代修复代码中的作用。

### 2. 方法论：核心思想与技术细节
*   **核心思想**：构建一个自动化的“生成-校验-反馈-修正”闭环。
*   **技术流程**：
    1.  **初始生成**：LLM 根据自然语言 Prompt 生成 ABAP 全局类代码。
    2.  **自动化部署**：通过 Python 控制器利用 **ADT (ABAP Development Tools) 接口**，将代码自动上传至 SAP Docker 容器（ABAP Cloud 2023 运行环境）。
    3.  **多级校验**：系统依次进行“类创建”、“语法检查”和“单元测试（ABAP Unit）”执行。
    4.  **迭代反馈**：若失败，系统捕获编译器报错信息或测试失败日志，反馈给 LLM 进行修正。
    5.  **终止条件**：代码通过所有测试或达到最大迭代次数（5 次）。
*   **评估模型**：引入了 **Kaplan-Meier 生存分析**（通常用于医学领域），将“代码错误状态”视为“生存”，将“修复成功”视为“事件”，以此量化模型随迭代次数增加的性能提升曲线。

### 3. 实验设计
*   **数据集/Benchmark**：共 180 个任务。
    *   **164 个改编任务**：源自经典的 HumanEval（Python），将其逻辑迁移至 ABAP 环境。
    *   **16 个 SAP 实际场景**：侧重于数据库操作（OpenSQL）、内部表处理等真实业务逻辑。
*   **任务分类**：字符串处理、列表/数组操作、数学计算、逻辑条件、ABAP 数据库操作。
*   **对比方法（模型选择）**：
    *   **闭源领先模型**：GPT-5 (2025-08-07 版)、Claude-Sonnet-4。
    *   **开源/专业模型**：Llama-3.3-70B、Codestral-22B、Qwen2.5-Coder、Qwen3-Coder、GPT-OSS (20B/120B)。

### 4. 资源与算力
*   **算力支持**：论文提到使用了“KISSKI 敏感与关键基础设施 AI 服务中心”和“THK-AI 研究集群”的计算资源。
*   **具体细节**：文中**未明确说明**具体的 GPU 型号、数量或推理总时长。实验环境基于 `sapse/abap-cloud-developer-trial:2023` Docker 镜像。

### 5. 实验数量与充分性
*   **实验规模**：每个任务重复 **10 次**实验以消除 LLM 生成的随机性影响。总计进行了 $180 \times 10 = 1800$ 组独立的迭代实验。
*   **充分性评价**：
    *   **客观性**：使用了自动化的单元测试作为硬性指标，避免了人工评估的主观偏差。
    *   **公平性**：所有模型使用统一的 System Prompt（除了 GPT-5 因 API 限制无法调整温度外，其余模型 Temperature 均设为 0.2）。
    *   **统计严谨性**：引入生存分析和 95% 置信区间，使结论具备统计学意义。

### 6. 主要结论与发现
*   **迭代反馈是关键**：初始轮次（Round 0）成功率极低（最强模型仅约 20%），但经过 5 轮反馈后，GPT-5 和 Claude-Sonnet-4 的成功率飙升至 **75%-77%**。
*   **模型梯队分化**：GPT-5 和 Claude 处于第一梯队；开源模型（如 GPT-OSS-120B）虽有进步但差距明显；Codestral-22B 因无法严格遵循 Markdown 格式要求，成功率为 0%。
*   **任务难度差异**：**列表/数组操作**最难（有 19 个任务所有模型均无法解决）；**数据库操作**虽然领域特定，但模型表现反而相对稳健。
*   **双峰分布特征**：模型对某一任务要么在极少轮次内解决，要么彻底无法解决，存在明显的“逻辑断层”。

### 7. 优点与亮点
*   **填补空白**：这是首个针对 ABAP 语言的大规模、自动化、基于编译器反馈的实证研究。
*   **真实环境**：并非简单的文本匹配，而是在真实的 SAP 内核上运行代码并执行单元测试，结果极具说服力。
*   **方法论创新**：将生存分析引入代码生成评估，直观展示了模型利用反馈进行“学习”的效率。

### 8. 不足与局限
*   **任务复杂度有限**：虽然包含数据库操作，但仍缺乏跨系统集成、复杂权限校验或大规模遗留代码