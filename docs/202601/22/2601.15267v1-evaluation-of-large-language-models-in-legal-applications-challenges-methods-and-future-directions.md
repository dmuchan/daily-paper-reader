# Evaluation of Large Language Models in Legal Applications: Challenges, Methods, and Future Directions
# 大语言模型在法律应用中的评估：挑战、方法与未来方向

**Authors**: Yiran Hu, Huanghai Liu, Chong Wang, Kunran Li, Tien-Hsuan Wu, Haitao Li, Xinran Xu, Siqing Huo, Weihang Su, Ning Zheng, Siyuan Zheng, Qingyao Ai, Yun Liu, Renjun Bian, Yiqun Liu, Charles L. A. Clarke, Weixing Shen, Ben Kao
**Date**: 2026-01-21
**PDF**: https://arxiv.org/pdf/2601.15267v1
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">query:大厂llm</span>
**Score**: 7.0
**Evidence**: systematic evaluation and benchmarking of LLMs in specialized domains

---

## Abstract
Large language models (LLMs) are being increasingly integrated into legal applications, including judicial decision support, legal practice assistance, and public-facing legal services. While LLMs show strong potential in handling legal knowledge and tasks, their deployment in real-world legal settings raises critical concerns beyond surface-level accuracy, involving the soundness of legal reasoning processes and trustworthy issues such as fairness and reliability. Systematic evaluation of LLM performance in legal tasks has therefore become essential for their responsible adoption. This survey identifies key challenges in evaluating LLMs for legal tasks grounded in real-world legal practice. We analyze the major difficulties involved in assessing LLM performance in the legal domain, including outcome correctness, reasoning reliability, and trustworthiness. Building on these challenges, we review and categorize existing evaluation methods and benchmarks according to their task design, datasets, and evaluation metrics. We further discuss the extent to which current approaches address these challenges, highlight their limitations, and outline future research directions toward more realistic, reliable, and legally grounded evaluation frameworks for LLMs in legal domains.

## 摘要
大语言模型（LLMs）正越来越多地被集成到法律应用中，包括司法决策支持、法律实务辅助以及面向公众的法律服务。尽管 LLMs 在处理法律知识和任务方面展现出强大潜力，但其在真实法律场景中的部署引发了超越表面准确性的关键担忧，涉及法律推理过程的合理性以及公平性和可靠性等可信性问题。因此，对 LLMs 在法律任务中的表现进行系统性评估，对于其负责任的采用至关重要。本综述识别了基于真实法律实务评估 LLMs 法律任务表现的关键挑战。我们分析了评估法律领域 LLM 性能的主要难点，包括结果正确性、推理可靠性和可信性。基于这些挑战，我们根据任务设计、数据集和评估指标，对现有的评估方法

---

## 速览摘要（自动生成）

**问题**：法律大模型在实务中面临推理不可靠、公平性欠