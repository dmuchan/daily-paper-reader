# The Plausibility Trap: Using Probabilistic Engines for Deterministic Tasks
# 合理性陷阱：将概率引擎用于确定性任务

**Authors**: Ivan Carrera, Daniel Maldonado-Ruiz
**Date**: 2026-01-21
**PDF**: https://arxiv.org/pdf/2601.15130v1
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">query:大厂llm</span>
**Score**: 7.0
**Evidence**: benchmarking LLM efficiency and probabilistic vs deterministic task performance

---

## Abstract
The ubiquity of Large Language Models (LLMs) is driving a paradigm shift where user convenience supersedes computational efficiency. This article defines the "Plausibility Trap": a phenomenon where individuals with access to Artificial Intelligence (AI) models deploy expensive probabilistic engines for simple deterministic tasks-such as Optical Character Recognition (OCR) or basic verification-resulting in significant resource waste. Through micro-benchmarks and case studies on OCR and fact-checking, we quantify the "efficiency tax"-demonstrating a ~6.5x latency penalty-and the risks of algorithmic sycophancy. To counter this, we introduce Tool Selection Engineering and the Deterministic-Probabilistic Decision Matrix, a framework to help developers determine when to use Generative AI and, crucially, when to avoid it. We argue for a curriculum shift, emphasizing that true digital literacy relies not only in knowing how to use Generative AI, but also on knowing when not to use it.

## 摘要
大语言模型（LLMs）的普及正在推动一场范

---

## 速览摘要（自动生成）

**问题**：用户滥用昂贵的大模型处理OCR等简单确定性任务，陷入