# Automated Rubrics for Reliable Evaluation of Medical Dialogue Systems
# 医疗对话系统可靠评估的自动化评分标准

**Authors**: Yinzhu Chen, Abdine Maiga, Hossein A. Rahmani, Emine Yilmaz
**Date**: 2026-01-21
**PDF**: https://arxiv.org/pdf/2601.15161v1
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">query:大厂llm</span>
**Score**: 6.0
**Evidence**: evaluation framework for large language models using automated rubrics

---

## Abstract
Large Language Models (LLMs) are increasingly used for clinical decision support, where hallucinations and unsafe suggestions may pose direct risks to patient safety. These risks are particularly challenging as they often manifest as subtle clinical errors that evade detection by generic metrics, while expert-authored fine-grained rubrics remain costly to construct and difficult to scale. In this paper, we propose a retrieval-augmented multi-agent framework designed to automate the generation of instance-specific evaluation rubrics. Our approach grounds evaluation in authoritative medical evidence by decomposing retrieved content into atomic facts and synthesizing them with user interaction constraints to form verifiable, fine-grained evaluation criteria. Evaluated on HealthBench, our framework achieves a Clinical Intent Alignment (CIA) score of 60.12%, a statistically significant improvement over the GPT-4o baseline (55.16%). In discriminative tests, our rubrics yield a mean score delta ($μ_Δ = 8.658$) and an AUROC of 0.977, nearly doubling the quality separation achieved by GPT-4o baseline (4.972). Beyond evaluation, our rubrics effectively guide response refinement, improving quality by 9.2% (from 59.0% to 68.2%). This provides a scalable and transparent foundation for both evaluating and improving medical LLMs. The code is available at https://anonymous.4open.science/r/Automated-Rubric-Generation-AF3C/.

## 摘要
大语言模型（LLMs）正越来越多地应用于临床决策支持，但

---

## 速览摘要（自动生成）

**问题**：医疗大模型存在幻觉与安全风险，传统指标难以捕捉细