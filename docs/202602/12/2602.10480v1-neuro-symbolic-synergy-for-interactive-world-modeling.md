---
title: Neuro-Symbolic Synergy for Interactive World Modeling
title_zh: 交互式世界建模的神经符号协同
authors: "Hongyu Zhao, Siyu Zhou, Haolin Yang, Zengyi Qin, Tianyi Zhou"
date: 2026-02-11
pdf: "https://arxiv.org/pdf/2602.10480v1"
tags: ["keyword:SR", "query:SR"]
score: 8.0
evidence: 用于世界建模的神经符号协同
tldr: "针对大语言模型在世界建模中易产生幻觉且符号模型缺乏语义表达力的问题，本文提出NeSyS框架。该框架通过将LLM的概率语义先验与可执行符号规则相结合，利用符号规则直接约束LLM的输出概率分布，并在两者间交替训练。实验证明，NeSyS在ScienceWorld等多个交互式环境中显著提升了预测准确率，且在保持精度的前提下减少了50%的训练数据需求。"
motivation: 旨在解决大语言模型在处理确定性逻辑规则时易幻觉，以及传统符号模型在复杂语义环境下表达力不足的局限性。
method: 提出一种神经-符号协同框架，通过符号规则约束LLM输出分布，并仅针对符号规则无法覆盖的轨迹对神经模型进行微调。
result: "在ScienceWorld、Webshop和Plancraft三个环境中的实验表明，该方法在提高预测准确性的同时，将训练数据量降低了50%。"
conclusion: 神经-符号协同机制能有效结合LLM的语义先验与符号逻辑的鲁棒性，实现更高效且精确的交互式世界建模。
---

## 摘要
大语言模型（LLMs）展现出强大的通用推理能力，但当作为世界模型（WMs）使用时，它们经常产生幻觉，而世界模型要求严格遵守确定性的状态转移规则，尤其是在极端情况下。相比之下，符号化世界模型提供了逻辑一致性，但缺乏语义表达能力。为了弥补这一差距，我们提出了神经符号协同（NeSyS）框架，该框架将 LLMs 的概率语义先验与可执行的符号规则相结合，以同时实现表达能力和鲁棒性。NeSyS 利用对方无法充分解释的轨迹，在两个模型之间进行交替训练。与基于规则的提示不同，符号化世界模型通过修改 LLM 的输出概率分布来直接对其进行约束。神经世界模型仅在符号规则未覆盖的轨迹上进行微调，在不损失准确性的情况下减少了 50% 的训练数据。在 ScienceWorld、Webshop 和 Plancraft 三个不同的交互式环境上进行的广泛实验表明，NeSyS 在世界模型预测准确率和数据效率方面均展现出优于基线模型的一致优势。

## Abstract
Large language models (LLMs) exhibit strong general-purpose reasoning capabilities, yet they frequently hallucinate when used as world models (WMs), where strict compliance with deterministic transition rules--particularly in corner cases--is essential. In contrast, Symbolic WMs provide logical consistency but lack semantic expressivity. To bridge this gap, we propose Neuro-Symbolic Synergy (NeSyS), a framework that integrates the probabilistic semantic priors of LLMs with executable symbolic rules to achieve both expressivity and robustness. NeSyS alternates training between the two models using trajectories inadequately explained by the other. Unlike rule-based prompting, the symbolic WM directly constrains the LLM by modifying its output probability distribution. The neural WM is fine-tuned only on trajectories not covered by symbolic rules, reducing training data by 50% without loss of accuracy. Extensive experiments on three distinct interactive environments, i.e., ScienceWorld, Webshop, and Plancraft, demonstrate NeSyS's consistent advantages over baselines in both WM prediction accuracy and data efficiency.

---

## 论文详细总结（自动生成）

这是一份关于论文《Neuro-Symbolic Synergy for Interactive World Modeling》的结构化深入分析报告：

### 1. 核心问题与整体含义（研究动机和背景）
论文探讨了在交互式环境中构建“世界模型”（World Model, WM）的挑战。
*   **研究动机**：大语言模型（LLMs）虽然具备强大的语义推理能力，但在处理需要严格遵守确定性规则（如游戏逻辑、网页导航协议）的场景时，容易产生“幻觉”，且难以覆盖长尾的极端情况。
*   **背景矛盾**：纯神经模型（LLM）概率性强但逻辑严谨性不足；纯符号模型（Symbolic WM）逻辑严密但无法处理复杂的自然语言语义。
*   **核心问题**：如何有效结合两者的优势，既保留 LLM 的语义表达力，又确保世界模型遵循物理或逻辑的硬约束。

### 2. 方法论：核心思想与关键技术
论文提出了 **NeSyS (Neuro-Symbolic Synergy)** 框架，其核心思想是**通过符号规则直接干预神经模型的概率分布**，而非简单的 Prompt 注入。

*   **概率分布修改（核心技术）**：
    符号模型被实现为一组加权的 Python 函数。对于候选的下一个状态 $s_i$，LLM 计算其原始似然概率 $p_i$，符号规则计算一个能量项 $E_i = \sum w_j e_{ij}$。最终的修改后概率为：
    $$\tilde{p}_i = p_i \exp(\gamma E_i)$$
    这种方式允许符号规则通过负能量实施“硬约束”，或通过正能量提升逻辑一致性。
*   **两阶段训练流程（互惠精炼）**：
    1.  **初始化阶段**：使用预训练 LLM 识别错误，通过自动化循环（Error Clustering -> GPT-5-mini 生成 Python 规则 -> 验证）构建初始符号规则库。
    2.  **互惠精炼阶段**：
        *   **规则引导的数据选择**：过滤掉符号规则已经能完美处理的简单样本，仅保留符号模型无法解释的“硬样本”来微调神经模型。
        *   **规则更新**：在微调后的神经模型基础上，针对残余错误进一步诱导和优化符号规则及其权重。

### 3. 实验设计
*   **实验场景（三个多样化环境）**：
    1.  **ScienceWorld**：考察小学水平的物理常识推理。
    2.  **Webshop**：考察真实的网页导航与电子商务交互逻辑。
    3.  **Plancraft**：基于 Minecraft 的合成任务，考察对游戏规则的严格遵守。
*   **Benchmark 与对比方法**：
    *   **骨干模型**：Llama 3.2-1B-Instruct, Qwen 3-4B。
    *   **对比基线**：包括 Llama 3.1-8B, Qwen 3-8B/14B, Phi-4-mini, GPT-oss-20B 以及强力的 GPT-5-mini。
    *   **消融对比**：纯 SFT（全量数据微调）、纯神经模型、纯符号模型。

### 4. 资源与算力
*   **模型使用**：使用了开源模型（Llama, Qwen）进行本地微调和推理，并调用了闭源模型（GPT-5-mini）用于规则的自动生成和诱导。
*   **算力细节**：论文**未明确说明**具体的 GPU 型号、数量或训练总时长。但提到通过数据选择策略，训练数据量减少了约 50%，暗示了该方法在计算资源上的高效性。

### 5. 实验数量与充分性
*   **实验规模**：在三个截然不同的领域进行了测试，涵盖了从物理常识到结构化游戏逻辑的多种维度。
*   **消融实验**：详细对比了 Phase 1 和 Phase 2 的性能提升，并专门设计了实验验证“规则引导数据选择”优于“随机数据选择”。
*   **客观性**：通过在不同规模（1B 到 4B）的骨干模型上取得一致的性能提升，证明了方法的普适性。实验设计考虑了数据效率和预测准确率的双重指标，评价较为全面。

### 6. 主要结论与发现
*   **协同效应显著**：NeSyS 在所有环境中均优于纯神经或纯符号模型。例如在 ScienceWorld 中，仅用 45% 的数据就超过了 100% 数据全量微调的基线。
*   **数据效率提升**：通过剔除符号规则可覆盖的冗余数据，微调过程更加聚焦于复杂、直觉性的动态模拟，显著降低了训练成本。
*   **鲁棒性增强**：在 Plancraft 等易发生“灾难性遗忘”的环境中，符号组件作为“锚点”确保了基础规则（如熔炼逻辑）不会因神经微调而失效。

### 7. 优点（亮点）
*   **非侵入式约束**：通过修改 Logits 而非修改 Prompt，避免了小模型不听从指令（Instruction-following）的问题。
*   **互补式进化**：提出的两阶段训练法让神经和符号组件能够针对彼此的弱点进行迭代，形成了良性循环。
*   **高效率**：规则引导的数据筛选机制为 LLM 的高效微调提供了新思路。

### 8. 不足与局限
*   **规则生成依赖**：符号规则的诱导高度依赖于高性能模型（如 GPT-5-mini）的编程能力，若底层模型代码生成能力弱，框架效果可能受限。
*   **路由机制尚浅**：虽然尝试了 XGBoost 路由，但效果提升有限，如何更智能地在神经和符号路径间动态切换仍有待研究。
*   **候选集依赖**：推理过程依赖于候选状态的生成或提供，对于动作空间极度发散且无候选集的场景，计算开销可能会增加。

（完）
